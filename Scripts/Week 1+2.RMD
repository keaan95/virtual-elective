---
title: "Practical Coding Exercises in Machine Learning in R"
author: "Keaan Amin"
date: 'Last Modified: 6th May 2021'
output:
  slidy_presentation: default
  beamer_presentation: default
  ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Purpose of this Series

- Learn Basic Functions in R [Week 1]
- Building your First Models in ML [Week 2]
- Visualise, Improve and Optimise your Models [Week 3]
- Develop Models on New Data Top to Toe [Week 4]


## Getting Started [before the session to be completed]

R is a program available on  your computer.
RStudio is a program that allows to visualise outputs from

1. Install the Latest Base Package of R from below:

http://www.r-project.org/

2. Install Rstudio (if comfortable operating + projecting R plots at the command line - omit this step):

https://rstudio.com/products/rstudio/download/#download

3. Review the Introduction to R Video - Dr Skorupska

## Getting Help Once Live

1. Ask Google - Stackoverflow - lots of solutions

2. Ask R for help
?help(package="stats")

3. Package Documentation - Google

4. Google and use StackOverflow.com

## What's R?

- A free language for statistical dataset analysis
- Enormous graphical capabilities through well-supported packages
- Interpretative language so commands are typed without requiring to build complete programmes
- Well-supported and documented modular add-on packages (16,000!) - across Stats, ML and ComputerBio
- Less learning -> more doing -> more problem-solving.

## How is it different to Excel or stats programmes e.g. SPSS?

![Lots of additional packages and resources to do more computational tasks. Shift through thousands of columns of data, visualise and adapt plots more quickly. Lots more creative capacity](https://iqss.github.io/dss-workshops/R/Rintro/images/R_chain.png)

## How does R work?

![Apply our code as keyboard commands that interact with our workspace. Import data e.g. as txt or csv files that can be exported to use in other programmes. Produce plots.](https://iqss.github.io/dss-workshops/R/Rintro/images/R_works.png)

## Major Uses of R

![test](https://revolution-computing.typepad.com/.a/6a010534b1db25970b0147e0ae51b2970b-800wi){width=30%}
![test](https://i.ibb.co/V2jDg48/burns-ft-covid-case-trajectory-1.jpg){width=20%}
![test](https://fivethirtyeight.com/wp-content/uploads/2016/11/morris-durant-1b.png){width=15%}
![test](https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs42003-020-01172-0/MediaObjects/42003_2020_1172_Fig2_HTML.png){width=15%}

- Social Networks
- Major News Corporations
- Sports and Politics
- Academia

## Machine Learning

![ML](https://t-dab.com/wp-content/uploads/2020/06/classification-of-the-most-common-machine-learning-algorithms2-1024x640.png)

## Install Packages

```{r,echo=TRUE}
# hashtags(#) denote a comment
# install.packages("caret")
# install.packages("ggplot2")
```

Load in our packages

```{r,echo=TRUE}
# library(ggplot2)
```

## Exercise 1 - Data Structures

Most commonly data is brought into R by txt and csv files:

```{r,echo=TRUE}
# You can fetch your WORKING directory as follows
getwd()
# Change to your local directory - in my case it is as follows:
# setwd("C:/Users/keaan/OneDrive - Newcastle University/HLA - Virtual Elective/Week1/")
df <- read.csv("data.csv", sep=",",header=T,row.names = 1)
```
## Whistle stop syntax

We can operate from the command line like a calculator:

```{r,echo=TRUE}
5+15
```

A *variable* is a letter or word that is assigned a value.

```{r,echo=TRUE}
x <- 10
x
y <- 5
y
```

R will automatically add variables of the same type e.g. integers.

```{r,echo=TRUE}

y+x
```

## Whistle stop Syntax

We can combine variables, in this characters to form a string:

```{r,echo=TRUE}
z <- c("ER","PR","HR")
z
```

Essentially, a series of strings make an object and our object is df [dataframe]. In other words, strings make up columns.

## Search in a String / Column

We can search for a particular value in a string by sequence number:

```{r,echo=TRUE}
z[1]
z[1:3]
z[-1]
```

We can ask if a particular value is in a string

```{r, echo=TRUE}
z=="PR"
z[z=="PR"]
```

## EXERCISE 2.1 - Data visualisation

Lets take a look at the breast data

```{r,echo=TRUE}
head(df)
df[1:5,1:5]
```

SO we have a dataframe but exactly is composed of this?

```{r,echo=TRUE}
str(df)
with(df, table(diagnosis))
```


## EXERCISE 2.2

1. How many patients are in the data?

## EXERCISE 2.2

```{r,echo=TRUE}
nrow(df)
```


## EXERCISE 2.3 - Scatterplots

Letâ€™s Plot Radius against Perimeter Means of Our Patients

## EXERCISE 2.3

- Building graphs in R is like painting a picture.
- Elements are added one layer at a time + built up in levels

```{r,echo=TRUE}
plot(df$radius_mean,df$texture_mean)
```

```{r,echo=TRUE}
plot(df$radius_mean,df$texture_mean,
col=as.factor(df$diagnosis),
xlab="Radius Means",
ylab="Texture Means",
main="Breast Cancer Patients of Radius against Texture Means")
legend("topright",legend = c("M", "B"), pch=c(1,1), col=c("red","black"))
```


## Building our First - Histograms in Base R

Let's see how our data across looks across one variable e..g perimeter mean

```{r,echo=TRUE}
hist(df$perimeter_mean)
hist(df$perimeter_mean,col="purple")
hist(df$perimeter_mean,col="purple",xlab="Perimeter Mean")
hist(df$perimeter_mean,col="purple",xlab="Perimeter Mean",main="Distribution of Perimeter")
```

## Layering Plots using Base R

- We first need to separate our variables into two strings

```{r, echo=TRUE}
hist_b <- df$perimeter_mean[df$diagnosis=="B"]
hist_m <- df$perimeter_mean[df$diagnosis=="M"]
```


## How does this compare across both groups?

- Plot them over each other to create separation [don't copy this!]

```{r,echo=TRUE}

# First distribution
plot.new()
hist(hist_b, breaks=10, xlim=c(0,250), col=rgb(0,0,1,0.5), xlab="Perimeter Mean", 
     ylab="Density", main="Perimeter Mean across Breast Tissue Types" )

# Second with add=T to plot on top
hist(hist_m, breaks=10, xlim=c(0,250), col=rgb(1,0,0,0.5), add=T)

# Add legend
legend("topright", legend=c("Benign","Malignant"), col=c(rgb(0,0,1,0.5), 
                                                         rgb(1,0,0,0.5)), pt.cex=2, pch=15 )

```

## How can we simplify plot making?

- Packages!

```{r, echo=TRUE}
library("ggplot2")
```


## Problems for Next Week!

- How can we distinguish between our variables to see which ones help to separate our two groups?
- What plots would you like to build to help us choose variables for our models?


## Next Week

- Further reading - caret (machine learning package) - http://www.rebeccabarter.com/blog/2017-11-17-caret_tutorial/, ggplot2 (graphical images package) - http://r-statistics.co/Complete-Ggplot2-Tutorial-Part1-With-R-Code.html, 
- Shall release Week 2 Mini-Exercises this weekend - feature selection [step 1 of building our models!]
- No Formal Coding Homework for Week 1!


## Week 1 Questions

- How can we distinguish between our variables to see which ones help to separate our two groups?
- We could plot histograms for all our variables or use scatterplots
- We could alternatively use correlations


## Correlations

- First we need a dataframe of pure numbers so lets kick out the diagnosis [we made a pdata and rownames are still intact]

```{r,echo=TRUE}
dfint <- df[, !(colnames(df) %in% c("diagnosis"))]
```

- Correlations to two decimal places

```{r,echo=TRUE}
cormat <- round(cor(dfint),2)
```

- Let's try out ggplot [a highly adaptable and well-supported graphics package to avoid layering our data + customise plots more easily]

We first need to do some data manipulation - we need all our data correlations into three columns.

```{r,echo=TRUE}
library(reshape2)
melted_cormat <- melt(cormat)
head(melted_cormat)
```

- Let's make our first correlation plot

```{r,echo=TRUE}
library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile(color = "white")
```

- Let's add some colours and twist the labels

```{r,echo=TRUE}
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()
```

- If one or more variables are more correlated, this suggests one is depenent on the other.
- An algorithm will assume and estimate relationships based on independent variables.
- Based on the algorithm we selection, we may miss out on dependent details 
- We are therefore at a risk of overfitting and to avoid this we can remove correlated variables. This may incur further repercussions...

## Week 2

- Building our first Model
- Testing out a laundry list of Algorithms
- Beginning to explaining Algorithms to members of the team

## Feature Selection

- In other words what variables shall we use for our model?
- We can use our expertise / experience as clinicians to pick out what is relevant.
- We can feature select by mathematical methods [Week 3]
- We can just take some variables, eyeballed from our correlations plot (a Filter Method).

```{r,echo=TRUE}
df_filt <- df[, colnames(df) %in% c("radius_mean","texture_mean","perimeter_mean","area_mean","diagnosis")]
```

## Automatic Boxplots and Histograms

- Caret is an R package with a library of models - a virtual ToysRus - convienently contains plots as well

```{r,echo=TRUE}
require(caret)
plot.new()
featurePlot(x = df_filt[, 2:5], 
            y = as.factor(df_filt$diagnosis), 
            plot = "box",
            strip=strip.custom(par.strip.text=list(cex=.9)),
            scales = list(x = list(relation="free"), 
                          y = list(relation="free")))
```


```{r,echo=TRUE}
featurePlot(x = df_filt[, 2:5], 
            y = as.factor(df_filt$diagnosis), 
            plot = "density",
            strip=strip.custom(par.strip.text=list(cex=.7)),
            scales = list(x = list(relation="free"), 
                          y = list(relation="free")))
```

## Training and Test Splits

```{r,echo=TRUE}
# Create the training and test datasets
set.seed(100)
library(nnet)
library("e1071")
library("caret")
## install.packages("caretEnsemble")
library(caretEnsemble)

# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(df_filt$diagnosis, p=0.8, list=FALSE)

# Step 2: Create the training  dataset
trainData <- df_filt[trainRowNumbers,]

# Step 3: Create the test dataset
testData <- df_filt[-trainRowNumbers,]


##Lets make Cross-validation 10x as our control
control <- trainControl(method="cv", number=10)

##Assess performance by ROC
metric <- "ROC"
```

## Random Forests Algorithm

```{r,echo=TRUE}
results <- train(diagnosis~., data=trainData, method="rf", metric="ROC",
                 trControl = trainControl(method = "cv", number = 10,classProbs=TRUE,summaryFunction = twoClassSummary, savePredictions = T))
```

- Let's test out a different algorithms!

```{r,echo=TRUE}
alg_list <- c("rf", "glm", "gbm", "lda", "rpart", "nnet","svmRadial","knn")
set.seed(65)
?caretList
resultsList <- caretList(diagnosis~ ., data=trainData,methodList = alg_list,metric="ROC",
          trControl = trainControl(method = "cv", number = 10,classProbs=TRUE,summaryFunction = twoClassSummary,
                                   savePredictions = T))
```

## Which model is currently performing the best?

- Practically, as a test-run we've fired many different models

```{r,echo=TRUE}
resListdata <- resamples(resultsList)
?resamples
resListdata$values

dotplot(resListdata)
```

## How does our best performing model with unseen data?

```{r,echo=TRUE}
predictions <- predict(resultsList$knn,testData)
results<- confusionMatrix(predictions,as.factor(testData$diagnosis), positive="M")
```

- Lets save our best performing model

```{r,echo=TRUE}
saveRDS(resultsList$knn, "breast_cancer_model.RDS")
```

- We can load this back into R by

```{r,echo=TRUE}
# getwd()
# list.files()

bc_model <- readRDS("breast_cancer_model.RDS")
```

## Week 2 Round-up

- We have model is performing well but still is quite complex.
- Practically, we would usually start with a simple model - one that can be explainable e.g. a decision tree or by previous evidence-based knowledge, select one to work with.
- Once we have a simple model, we'll then fine-tune and optimise it [Week 3].
- We'll also introduce multi-classification problems, making predictions and have a mini-competition in Week 4.

##  BONUS Homework

How can we more easily compare training + test outputs on all our algorithms?

- Loops help us to do code repeatedly without writing out the code every-time

- In this case, loops can do some code on every value in a vector.

```{r,echo=TRUE}
numberlist <-1:10

for(i in numberlist){
  print(i)
}
```

- Loop on names in a list

```{r,echo=TRUE}
names(resultsList)  

for(alg in names(resultsList)){
  print(alg)
}
```


- Loop on names in a list and put it into a new list

predictionsList <- list()
confusionMatrixList <- list()

for (alg in names(resultsList)) {
  predictionsList[[alg]] <- predict(resultsList[[alg]],testData)
  confusionMatrixList[[alg]] <- confusionMatrix(predictionsList[[alg]],as.factor(testData$diagnosis), positive="M")
  print(alg)
}

```{r,echo=TRUE}
# predictionsList$svmRadial
# confusionMatrixList$svmRadial
# confusionMatrixList$svmRadial$byClass
```


##Bonus Week 2 Homework

- Lets compare + plot the performance on test + validation across all our models. A hint is below

```{r,echo=TRUE}
# as.data.frame(confusionMatrixList$svmRadial$byClass)
```

- Fancy creating an Ensembl? Models on Models?

https://cran.r-project.org/web/packages/caretEnsemble/vignettes/caretEnsemble-intro.html

